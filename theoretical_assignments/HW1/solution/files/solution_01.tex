\section{پاسخ.}

\subsection{الف.}
	\begin{redtext}
		با توجه به جدول \ref{tb1}، بردارهای $Y$ و $\hat{Y}$ به ترتیب برابرند با:
		\begin{equation*}
			Y = \begin{bmatrix} 2100 \\ 1980 \\ 1420 \\ 1100 \\ 1300 \end{bmatrix},\:\:\:\:\:\: \hat{Y} = \begin{bmatrix} 1964 \\ 2031 \\ 1368 \\ 1037 \\ 1500 \end{bmatrix}
		\end{equation*}
		
		حال با توجه به رابطه \ref{eq1} مقدار میانگین مربع خطا برابرست با:
	\begin{equation*}
		\begin{aligned}
			MSE(Y, \hat{Y}) & = \frac{1}{5} [ (1964 - 2100)^2 + (2031 - 1980)^2 + (1368 - 1420)^2 + (1037 - 1100)^2 + (1500 - 1300)^2 ] \\
			& = \frac{1}{5} [ 18496 + 2601 + 2704 + 3969 + 40000 ] \\
			& = \frac{1}{5} [67770]  \\
			& = 13554
		\end{aligned}
	\end{equation*}
	
	اولین مزیت این تابع هزینه، فهم آسان آن است. این تابع هزینه از مجذور اختلاف مقدار پیش‌بینی شده و برچسب بدست می‌آید که درواقع برای هر خطای بدست آمده، مساحت ناحیه اختلاف این دو مقدار را بیان می‌کند. دومین و یکی از مهم‌ترین مزیت‌های این تابع، \textbf{مشتق‌پذیر} بودن آن است. می‌دانیم که در بسیاری از الگوریتم‌های یادگیری، از الگوریتم گرادیان کاهشی برای بهینه‌سازی مسئله استفاده می‌کنیم در این روش برای بروزرسانی پارامترهای قابل یادگیری مدل، نیاز است که در هر مرحله مشتق تابع هزینه نسبت به تمامی پارامترهای قابل یادگیری\LTRfootnote{Trainable Parameters} مدل محاسبه شود. اما از معایب این تابع، می‌توان به حساس بودن به داده‌های پرت اشاره کرد. در بسیاری از مسائل یادگیری، داده‌ها به همراه یک نویز جمع‌آوری می‌شوند که این پدیده ممکن است روی مقدار بدست آمده از این تابع تأثیر چشم‌گیری بگذارد. از طرفی این تابع، به شدت به مقیاس داده‌ها نیز حساس است. بنابراین بهتر است از روش‌های نرمال‌سازی داده متناسب با مسئله نیز استفاده کرد.
	
\subsection{ب.}
	\subsubsection{معیار $R^2$.}
	رابطه این معیار ارزیابی برابرست با:
	\begin{equation}
			R^2 = 1 - \frac{SS_{res}}{SS_{tot}}
		\label{eq2}
	\end{equation}
	
	که در این‌جا $SS_{res}$ مجموع مربعات باقیمانده‌ها و $SS_{tot}$ مجموع مجذورات متناسب با واریانس داده‌ها می‌باشد که هرکدام نیز برابرند با:
	\begin{equation}
		SS_{res} = \sum_{i=1}^{N} (\hat{y}_i - y_i)^2
		\label{eq3}
	\end{equation}	
	
	\begin{equation}
		SS_{tot} = \sum_{i=1}^{N} (y_i - \bar{y})^2, \quad\quad \bar{y} = \frac{1}{N} \sum_{i=1}^{N} y_i
		\label{eq4}
	\end{equation}	
	که در این رابطه، پراکندگی داده‌ها نسبت به میانگین آن‌ها محاسبه شده و سپس نسبت گرفته می‌شود. خروجی این معیار طبیعتاً عددی بین ۰ و ۱ است و هرچه این عدد به سمت ۱ میل کند، به معنای حداکثر واریانس\LTRfootnote{High Variance} و حداقل بایاس\LTRfootnote{Low Bias} و هرچقدر به سمت ۰ میل کند، برعکس. به عبارت دیگر، هرچقدر این معیار به سمت ۱ برود، احتمال آن‌که مدل تخمین زده شده دچار بیش‌برازش\LTRfootnote{Overfitting} شده است بیشتر می‌شود. مقدار این معیار برای جدول \ref{tb1} برابرست با:
	\begin{equation*}
		\begin{aligned}
			SS_{res} & = [ (1964 - 2100)^2 + (2031 - 1980)^2 + (1368 - 1420)^2 + (1037 - 1100)^2 + (1500 - 1300)^2 ] \\
			& =  [ 18496 + 2601 + 2704 + 3969 + 40000 ] \\
			& =  67770 \\
			\bar{y} & = \frac{1}{5}[ 2100 + 1980 + 1420 + 1100 + 1300] = \frac{1}{5}[7900] = 1580 \\
			SS_{tot} & = [ (2100 - 1580)^2 + (1980 - 1580)^2 + (1420 - 1580)^2 + (1100 - 1580)^2 + (1300 - 1580)^2 ] \\
			& =  [ 270400 + 160000 + 25600 + 230400 + 78400 ] \\
			& =  764800 \\
		\end{aligned}
	\end{equation*}
	
	بنابراین داریم:
	\begin{equation*}
		\begin{aligned}
			R^2 & = 1 - \frac{SS_{res}}{SS_{tot}} = 1 - \frac{67770}{764800} \\
			& =  1 - 0.08861140 \\
			& =  0.91138859 \\
		\end{aligned}
	\end{equation*}	
	
	\subsubsection{معیار \textit{NMSE}.}
	این معیار، حالت نرمال شده معیار \text{MSE} (رابطه \ref{eq1}) می‌باشد \cite{poli1993use}. به نظر می رسد NMSE از میزان بایاس نسبت به مدل‌هایی که بیش از حد بیش‌برازش یا کم‌برازش شده‌اند اجتناب می کند و به پراکندگی مجموعه داده‌ها تاکید می‌کند \cite{chang2004air}. کمترین مقدار این معیار ارزیابی صفر و بیشترین آن یک است، همچنین رابطه آن به صورت زیر بیان می‌شود:
	\begin{equation}
		\begin{aligned}
			NMSE = \frac{\overline{(\hat{Y} - Y)^2}} {\overline{\hat{Y}} \overline{Y}}
		\end{aligned}
		\label{eq5}
	\end{equation}
	که در این‌جا، $Y$ و $\hat{Y}$ به ترتیب برابر با بردار برچسب و پیش‌بینی و $\overline{Y}$ و $\overline{\hat{Y}}$ نیز به ترتیب میانگین این دو بردار هستند. همچنین مقدار $\overline{(\hat{Y} - Y)^2}$ میانگین تفاضل این دو بردار است که در صورت کسر قرار می‌گیرد. عدد حاصل از این معیار عددی نرمال شده و بین صفر و یک است که می‌تواند در تحلیل و میزان حساسیت به داده‌های پرت از اهمیت بالایی برخوردار باشد. مقدار این معیار ارزیابی برای جدول \ref{tb1} برابرست با:
	\begin{equation*}
		\begin{aligned}
			\overline{(\hat{Y} - Y)^2} & = \frac{1}{5} \sum_{i=1}^{5} (\hat{y}_i - y)^2 = 13554 \\
			\overline{Y} & = 1580 \\
			\overline{\hat{Y}} & = 1580 \\
			NMSE & = \frac{13554}{1580 \times 1580} = 0.00542941 \\
		\end{aligned}
	\end{equation*}	
	که این مقدار هر چه به صفر نزدیک باشد، نشان از آن است که عملکرد مدل خوب بوده است.
\end{redtext}
